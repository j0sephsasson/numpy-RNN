{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5682ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b665f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Vocabulary\n",
    "from embedding import EmbeddingLayer\n",
    "from lstm import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f2426",
   "metadata": {},
   "source": [
    "### MY EMBEDDING VS KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9c72c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2829, 25, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(r\"data\\alice_wonderland.txt\", 'r', encoding='utf-8').readlines()\n",
    "\n",
    "## create vocabulary + tokenize\n",
    "vocab = Vocabulary()\n",
    "token_sequences = vocab.tokenize(f, 26)\n",
    "\n",
    "## create embedding layer\n",
    "embedding = EmbeddingLayer(vocab_size=vocab.size, hidden_dim=50) ## hidden_dim is a hyper-param\n",
    "\n",
    "## create X & Y datasets\n",
    "X = token_sequences[:,:-1]\n",
    "y = token_sequences[:,-1]\n",
    "\n",
    "lstm_inputs = embedding.predict(X)\n",
    "lstm_inputs.shape ## batch_size x seq_length x dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e6cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2829, 25, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab.size, 50, input_length=25))\n",
    "model.compile('rmsprop', 'mse')\n",
    "\n",
    "output_array = model.predict(X)\n",
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c4ee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_inputs.shape==output_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae01a8",
   "metadata": {},
   "source": [
    "### MY LSTM VS KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3966e5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2829, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klstm = tf.keras.layers.LSTM(100)\n",
    "\n",
    "output = klstm(output_array)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8789d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2829, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klstm1 = tf.keras.layers.LSTM(100)\n",
    "\n",
    "output1 = klstm1(lstm_inputs)\n",
    "\n",
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d476eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_weights = klstm1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696585f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlstm = LSTM(100, vocab.seq_length, lstm_inputs.shape[0], vocab.size, embedding.hidden_dim)\n",
    "nlstm._init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d12e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSTM_UWb(weight):\n",
    "    '''\n",
    "    weight must be output of LSTM's layer.get_weights()\n",
    "    W: weights for input\n",
    "    U: weights for hidden states\n",
    "    b: bias\n",
    "    '''\n",
    "    warr,uarr, barr = weight\n",
    "    gates = [\"i\",\"f\",\"c\",\"o\"]\n",
    "    hunit = uarr.shape[0]\n",
    "    U, W, b = {},{},{}\n",
    "    for i1,i2 in enumerate(range(0,len(barr),hunit)):\n",
    "        \n",
    "        W[gates[i1]] = warr[:,i2:i2+hunit]\n",
    "        U[gates[i1]] = uarr[:,i2:i2+hunit]\n",
    "        b[gates[i1]] = barr[i2:i2+hunit].reshape(hunit,1)\n",
    "    return(W,U,b)\n",
    "\n",
    "W, U, b = get_LSTM_UWb(lstm_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13453e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100) (100, 100) (100, 1)\n",
      "(50, 100) (100, 100) (100, 1)\n",
      "(50, 100) (100, 100) (100, 1)\n",
      "(50, 100) (100, 100) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(W['i'].shape, U['i'].shape, b['i'].shape)\n",
    "print(W['f'].shape, U['f'].shape, b['f'].shape)\n",
    "print(W['c'].shape, U['c'].shape, b['c'].shape)\n",
    "print(W['o'].shape, U['o'].shape, b['o'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b49c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 125) (100, 50) (100, 1)\n",
      "(100, 125) (100, 50) (100, 1)\n",
      "(100, 125) (100, 50) (100, 1)\n",
      "(100, 125) (100, 50) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(nlstm.W_i.shape, nlstm.h.shape, nlstm.b_i.shape)\n",
    "print(nlstm.W_f.shape, nlstm.h.shape, nlstm.b_f.shape)\n",
    "print(nlstm.W_g.shape, nlstm.h.shape, nlstm.b_g.shape)\n",
    "print(nlstm.W_o.shape, nlstm.h.shape, nlstm.b_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1f12993",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 100\n",
    "\n",
    "kernel = nlstm._init_orthogonal(np.random.randn(lstm_inputs.shape[-1], hidden * 4))\n",
    "kernel_i = kernel[:, :hidden]\n",
    "kernel_f = kernel[:, hidden: hidden * 2]\n",
    "kernel_c = kernel[:, hidden * 2: hidden * 3]\n",
    "kernel_o = kernel[:, hidden * 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3628d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100) (50, 100) (50, 100) (50, 100)\n"
     ]
    }
   ],
   "source": [
    "print(kernel_i.shape, kernel_f.shape, kernel_c.shape, kernel_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4decc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_kernel = nlstm._init_orthogonal(np.random.randn(hidden, hidden * 4))\n",
    "recurrent_kernel_i = recurrent_kernel[:, :hidden]\n",
    "recurrent_kernel_f = recurrent_kernel[:, hidden: hidden * 2]\n",
    "recurrent_kernel_c = recurrent_kernel[:, hidden * 2: hidden * 3]\n",
    "recurrent_kernel_o = recurrent_kernel[:, hidden * 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bd4d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) (100, 100) (100, 100) (100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(recurrent_kernel_i.shape, recurrent_kernel_f.shape, recurrent_kernel_c.shape, recurrent_kernel_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9cb9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.random.randn(hidden * 4, )\n",
    "bias_i = bias[:hidden]\n",
    "bias_f = bias[hidden: hidden * 2]\n",
    "bias_c = bias[hidden * 2: hidden * 3]\n",
    "bias_o = bias[hidden * 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a82205f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,) (100,) (100,)\n"
     ]
    }
   ],
   "source": [
    "print(bias_i.shape, bias_f.shape, bias_c.shape, bias_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf04745e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_tm1 = np.zeros((2829, hidden))\n",
    "h_tm1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49e7aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_test(inputs, hidden, return_sequences=False):\n",
    "    h_tm1 = np.zeros((hidden,))\n",
    "    c_tm1 = np.zeros((hidden,))\n",
    "    \n",
    "    h_state_out = []\n",
    "    \n",
    "    for batch in inputs:\n",
    "    \n",
    "        inputs_i = batch\n",
    "        inputs_f = batch\n",
    "        inputs_c = batch\n",
    "        inputs_o = batch\n",
    "\n",
    "        h_tm1_i = h_tm1\n",
    "        h_tm1_f = h_tm1\n",
    "        h_tm1_c = h_tm1\n",
    "        h_tm1_o = h_tm1\n",
    "\n",
    "        x_i = np.dot(inputs_i, kernel_i) + bias_i\n",
    "        x_f = np.dot(inputs_f, kernel_f) + bias_f\n",
    "        x_c = np.dot(inputs_c, kernel_c) + bias_c\n",
    "        x_o = np.dot(inputs_o, kernel_o) + bias_o\n",
    "\n",
    "        f = nlstm.sigmoid(x_f + np.dot(h_tm1_f, recurrent_kernel_f))\n",
    "        i = nlstm.sigmoid(x_i + np.dot(h_tm1_i, recurrent_kernel_i))\n",
    "        o = nlstm.sigmoid(x_o + np.dot(h_tm1_o, recurrent_kernel_o))\n",
    "        cbar = nlstm.sigmoid(x_c + np.dot(h_tm1_c, recurrent_kernel_c))\n",
    "        c = (f * c_tm1) + (i * cbar)\n",
    "        ht = o * nlstm.tanh(c)\n",
    "        \n",
    "        if return_sequences == True:\n",
    "            h_state_out.append(ht)\n",
    "        else:\n",
    "            h_state_out.append(ht[-1])\n",
    "        \n",
    "        h_tm1 = ht\n",
    "        c_tm1 = c\n",
    "    \n",
    "    return np.array(h_state_out)\n",
    "\n",
    "# test_out = f_test(lstm_inputs, 100)\n",
    "# test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "839a6992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2829, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out1 = f_test(lstm_inputs, 100)\n",
    "test_out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a663c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2829, 25, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klstm1 = tf.keras.layers.LSTM(100, return_sequences=True)\n",
    "\n",
    "output1 = klstm1(lstm_inputs)\n",
    "\n",
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52a4e466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebbdf06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c00ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = [100,100]\n",
    "flat_dims = tf.TensorShape(state_size).as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7eacb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state_size = [2829] + flat_dims\n",
    "t = tf.zeros(init_state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed237a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2829, 100, 100])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f865271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 100])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "184a1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([-0.06452696, -0.05335967,  0.27230436,  0.08514202, -0.1366195 ,\n",
       "       -0.03089291, -0.09995215, -0.10938603, -0.21541286, -0.16333014,\n",
       "        0.11085184,  0.02595731,  0.07698277, -0.24887118,  0.01225445,\n",
       "       -0.02336389,  0.03856047,  0.22259717,  0.24349211,  0.05290796,\n",
       "       -0.10337024,  0.02625424,  0.10869118,  0.01917277,  0.06314739,\n",
       "       -0.16500454,  0.04420947,  0.16458632, -0.01336981,  0.17161603,\n",
       "        0.12315603, -0.19418809,  0.05854382,  0.10265537, -0.22877784,\n",
       "        0.2929678 ,  0.02486943, -0.06912109,  0.13993773,  0.03032602,\n",
       "        0.20207252,  0.01584396, -0.00444488,  0.24728256, -0.09831952,\n",
       "       -0.02874447,  0.03790721,  0.0167274 ,  0.08847462, -0.10701214,\n",
       "       -0.04409536,  0.19067554, -0.15128121,  0.13191572, -0.10877167,\n",
       "        0.02176062,  0.08408661,  0.01290146,  0.07844293,  0.19560237,\n",
       "        0.2011749 ,  0.03956545, -0.12428977,  0.10971019,  0.22808734,\n",
       "        0.02379115,  0.00980738, -0.00655111, -0.14581618, -0.02843306,\n",
       "       -0.13704206, -0.0077192 , -0.1779012 ,  0.04381697,  0.300774  ,\n",
       "       -0.1095652 ,  0.01598581, -0.07732626,  0.15881357, -0.1465893 ,\n",
       "        0.08989962, -0.1638583 , -0.24570149, -0.07067441,  0.12906154,\n",
       "       -0.10692206,  0.1516121 ,  0.05969698,  0.21002692, -0.0178619 ,\n",
       "        0.01603806,  0.22360995,  0.05846261,  0.17769563,  0.22950685,\n",
       "       -0.01827941, -0.10064107,  0.2942694 ,  0.24264632,  0.03356862],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
